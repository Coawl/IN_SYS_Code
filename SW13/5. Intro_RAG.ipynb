{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c06aae49-29f4-48e4-b014-49b3c7aced8f",
   "metadata": {},
   "source": [
    "# IN_SYS - SW13 Exercise 5\n",
    "\n",
    "## Retrieval Augmented Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3676f0d8-6162-496c-8e5d-034f5d5b2d7a",
   "metadata": {},
   "source": [
    "#### RAG Pipeline with GPT-4 and OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02ed6bde-972e-4a97-a943-81d162a559f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import tiktoken\n",
    "import numpy as np\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load OpenAI API key\n",
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_API_KEY\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cec27a1-9085-4da7-8d7a-c355d930f997",
   "metadata": {},
   "source": [
    "#### Initialize tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65415d5-2b9d-42fa-8d0f-8e0518f7826a",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_tokenizer = tiktoken.encoding_for_model(\"gpt-4\")  # GPT-4 tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ae8ca-8940-4e02-88b9-39d6725b1fd8",
   "metadata": {},
   "source": [
    "#### HSLU Knowledge Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20f353a-1c3a-4ee6-b527-319e409150fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "hslu_chunks = [\n",
    "    \"HSLU has seven schools: Engineering and Architecture, Business, Computer Science, Social Work, Design Film and Art, Music, and Health Sciences.\",\n",
    "    \"The Engineering and Architecture school offers Business Engineering, Energy Engineering, and Digital Construction programs.\",\n",
    "    \"The Business school provides Business Administration, International Management, and Accounting degrees.\",\n",
    "    \"Computer Science department includes Software Engineering, Data Science, and IT programs.\",\n",
    "    \"Social Work focuses on counseling, social services, and social pedagogy.\",\n",
    "    \"Design Film and Art covers Graphic Design, Film production, and Fine Arts.\",\n",
    "    \"Music school has Music Performance, Composition, and Music Education.\",\n",
    "    \"Health Sciences offers Nursing, Physiotherapy, and Health Management programs.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941882f1-fb94-4800-8919-3455adb55e07",
   "metadata": {},
   "source": [
    "#### We will create chunk embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "debdc487-1630-4157-95a2-c787c4e3014e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for all chunks...\n",
      "Created 8 embeddings\n",
      "Each embedding: 3072 dimensions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def create_embeddings(texts):\n",
    "    embeddings = []\n",
    "    \n",
    "    for text in texts:\n",
    "        response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            input=text\n",
    "        )\n",
    "        embedding = response.data[0].embedding\n",
    "        embeddings.append(embedding)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "print(\"Creating embeddings for all chunks...\")\n",
    "chunk_embeddings = create_embeddings(hslu_chunks)\n",
    "print(f\"Created {len(chunk_embeddings)} embeddings\")\n",
    "print(f\"Each embedding: {len(chunk_embeddings[0])} dimensions\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303182fc-6b2f-43a0-b1f9-e38d8e86fede",
   "metadata": {},
   "source": [
    "#### We will simulate asking a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efd7259f-7e2a-4f7f-b4c0-c91bd6e3af2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 'Which school offers Business Engineering program?'\n"
     ]
    }
   ],
   "source": [
    "question = \"Which school offers Business Engineering program?\"\n",
    "print(f\"Question: '{question}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "942529f7-8c38-4008-95ad-5e469faae727",
   "metadata": {},
   "source": [
    "#### Let's see how the question is tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "850a1de6-39b3-4be7-affa-412179b64de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-4 Tokenization:\n",
      "  Token IDs: [23956, 2978, 6209, 8184, 17005, 2068, 30]\n",
      "  Token Texts: ['Which', ' school', ' offers', ' Business', ' Engineering', ' program', '?']\n",
      "  Token Count: 7\n"
     ]
    }
   ],
   "source": [
    "llm_question_token_ids = llm_tokenizer.encode(question)\n",
    "llm_question_token_texts = [llm_tokenizer.decode([t]) for t in llm_question_token_ids]\n",
    "\n",
    "print(f\"GPT-4 Tokenization:\")\n",
    "print(f\"  Token IDs: {llm_question_token_ids}\")\n",
    "print(f\"  Token Texts: {llm_question_token_texts}\")\n",
    "print(f\"  Token Count: {len(llm_question_token_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54746aa8-0f77-4183-8665-08036ba22845",
   "metadata": {},
   "source": [
    "#### Create question embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29af5353-44e7-48e0-a042-66f45ac45547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question embeddings vector created:\n",
      "    Vector dimensions: 3072\n",
      "    Sample (first 10): [-0.00805139821022749, 0.025078123435378075, -0.029882565140724182, 0.008935731835663319, -0.00026934235938824713, -0.01706632412970066, 0.02156718634068966, 0.026054851710796356, 0.006309127900749445, -0.04073215276002884]\n",
      "\n",
      "Embedding model uses CLIP tokenizer internally, which is different from GPT-4 tokenizer\n"
     ]
    }
   ],
   "source": [
    "question_embedding_response = client.embeddings.create(\n",
    "            model=\"text-embedding-3-large\",\n",
    "            input=question\n",
    ")\n",
    "question_embedding = question_embedding_response.data[0].embedding\n",
    "\n",
    "print(f\"Question embeddings vector created:\")\n",
    "print(f\"    Vector dimensions: {len(question_embedding)}\")\n",
    "print(f\"    Sample (first 10): {question_embedding[:10]}\")\n",
    "print()\n",
    "\n",
    "# Note: Embedding model uses its own internal tokenizer\n",
    "# OpenAI doesn't expose this, but we know it's different from GPT-4\n",
    "print(\"Embedding model uses CLIP tokenizer internally, which is different from GPT-4 tokenizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ee189f-590a-49d3-bfda-bd1f0e9a6e67",
   "metadata": {},
   "source": [
    "#### Vector similarity search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36565689-d7c1-4298-baf8-baefb6efb5c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Scores:\n",
      "  Chunk 2: 0.6647 ← TOP RESULT\n",
      "  Chunk 3: 0.5223\n",
      "  Chunk 1: 0.3881\n",
      "  Chunk 4: 0.3543\n",
      "  Chunk 8: 0.3536\n",
      "  Chunk 7: 0.2505\n",
      "  Chunk 6: 0.1862\n",
      "  Chunk 5: 0.1410\n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    \"\"\"Calculate cosine similarity between two vectors.\"\"\"\n",
    "    a = np.array(a)\n",
    "    b = np.array(b)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "# Calculate similarities\n",
    "similarities = []\n",
    "for i, chunk_embedding in enumerate(chunk_embeddings):\n",
    "    similarity = cosine_similarity(question_embedding, chunk_embedding)\n",
    "    similarities.append((i, similarity, hslu_chunks[i]))\n",
    "\n",
    "# Sort by similarity\n",
    "similarities.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Similarity Scores:\")\n",
    "for idx, score, chunk in similarities:\n",
    "    indicator = \" ← TOP RESULT\" if idx == similarities[0][0] else \"\"\n",
    "    print(f\"  Chunk {idx+1}: {score:.4f}{indicator}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502c5de4-d41f-4663-b48b-abcb4a7c4609",
   "metadata": {},
   "source": [
    "#### Get top-k chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0bc56b6a-34ba-4ee4-be0c-dc007483bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question: 'Which school offers Business Engineering program?'\n",
      "\n",
      "Top-2 most similar chunks:\n",
      "\n",
      "Chunk 2 (score: 0.6647):\n",
      "  'The Engineering and Architecture school offers Business Engineering, Energy Engineering, and Digital Construction programs.'\n",
      "\n",
      "Chunk 3 (score: 0.5223):\n",
      "  'The Business school provides Business Administration, International Management, and Accounting degrees.'\n"
     ]
    }
   ],
   "source": [
    "k = 2\n",
    "top_k = similarities[:k]\n",
    "\n",
    "print(f\"Question: '{question}'\")\n",
    "print(f\"\\nTop-{k} most similar chunks:\")\n",
    "for idx, score, chunk in top_k:\n",
    "    print(f\"\\nChunk {idx+1} (score: {score:.4f}):\")\n",
    "    print(f\"  '{chunk}'\")\n",
    "\n",
    "# Combine chunks for context\n",
    "retrieved_chunks = \"\\n\\n\".join([chunk for _, _, chunk in top_k])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b9d3cb-f7a4-4ac5-b87f-cfdbedd4c67f",
   "metadata": {},
   "source": [
    "#### Tokenize retrieved chunks with GPT-4 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb98eab-c4de-4561-ac72-aec7da765637",
   "metadata": {},
   "source": [
    "#### Build full RAG prompt consisting of question and chunks (context) and tokenize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5319f61e-7cb7-416a-b4fa-d0ffc64c38c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full Prompt:\n",
      "----------------------------------------\n",
      "Context: The Engineering and Architecture school offers Business Engineering, Energy Engineering, and Digital Construction programs.\n",
      "\n",
      "The Business school provides Business Administration, International Management, and Accounting degrees.\n",
      "\n",
      "Question: Which school offers Business Engineering program?\n",
      "----------------------------------------\n",
      "\n",
      "LLM Prompt Tokenization:\n",
      "  Total tokens: 42\n",
      "  Tokens: [2014, 25, 578, 17005, 323, 38943, 2978, 6209, 8184, 17005, 11, 12634, 17005, 11, 323, 14434, 24987, 7620, 382, 791, 8184, 2978, 5825, 8184, 17128, 11, 7327, 9744, 11, 323, 45344, 12628, 382, 14924, 25, 16299, 2978, 6209, 8184, 17005, 2068, 30]\n",
      "  Texts: ['Context', ':', ' The', ' Engineering', ' and', ' Architecture', ' school', ' offers', ' Business', ' Engineering', ',', ' Energy', ' Engineering', ',', ' and', ' Digital', ' Construction', ' programs', '.\\n\\n', 'The', ' Business', ' school', ' provides', ' Business', ' Administration', ',', ' International', ' Management', ',', ' and', ' Accounting', ' degrees', '.\\n\\n', 'Question', ':', ' Which', ' school', ' offers', ' Business', ' Engineering', ' program', '?']\n",
      "\n",
      "Token count check:\n",
      "  Prompt tokens: 42\n",
      "  GPT-4 context window: 8192 tokens\n",
      "  Status: Within limit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Build RAG prompt\n",
    "prompt = f\"\"\"Context: {retrieved_chunks}\n",
    "\n",
    "Question: {question}\"\"\"\n",
    "\n",
    "print(\"Full Prompt:\")\n",
    "print(\"-\"*40)\n",
    "print(prompt)\n",
    "print(\"-\"*40)\n",
    "print()\n",
    "\n",
    "# Tokenize entire prompt with LLM\n",
    "llm_prompt_tokens = llm_tokenizer.encode(prompt)\n",
    "llm_prompt_token_texts = [llm_tokenizer.decode([t]) for t in llm_prompt_tokens]\n",
    "\n",
    "print(f\"LLM Prompt Tokenization:\")\n",
    "print(f\"  Total tokens: {len(llm_prompt_tokens)}\")\n",
    "print(f\"  Tokens: {llm_prompt_tokens}\")\n",
    "print(f\"  Texts: {llm_prompt_token_texts}\")\n",
    "print()\n",
    "\n",
    "# Check token count (GPT-4 has 8k context window)\n",
    "print(f\"Token count check:\")\n",
    "print(f\"  Prompt tokens: {len(llm_prompt_tokens)}\")\n",
    "print(f\"  GPT-4 context window: 8192 tokens\")\n",
    "print(f\"  Status: {'Within limit' if len(llm_prompt_tokens) < 8000 else 'Close to limit'}\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7750dbec-9a0d-431c-90c2-66d00798fbf5",
   "metadata": {},
   "source": [
    "#### Get the answer from LLM (GPT-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f6f9be5b-4677-4401-aa40-14783e014043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling GPT-4 API...\n",
      "   GPT-4 Answer:\n",
      "   'The Engineering and Architecture school offers the Business Engineering program.'\n",
      "\n",
      "Answer Tokenization:\n",
      "  Token Count: 11\n",
      "  Token IDs: [791, 17005, 323, 38943, 2978, 6209, 279, 8184, 17005, 2068]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Calling GPT-4 API...\")\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant that answers questions based on the provided context.\"},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ],\n",
    "    temperature=0.7,\n",
    "    max_tokens=150\n",
    ")\n",
    "\n",
    "# Extract the answer\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "print(f\"   GPT-4 Answer:\")\n",
    "print(f\"   '{answer}'\")\n",
    "print()\n",
    "\n",
    "# Tokenize the answer to see GPT-4's output tokens\n",
    "llm_answer_token_ids = llm_tokenizer.encode(answer)\n",
    "print(f\"Answer Tokenization:\")\n",
    "print(f\"  Token Count: {len(llm_answer_token_ids)}\")\n",
    "print(f\"  Token IDs: {llm_answer_token_ids[:10]}...\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce102e0-b047-49b9-914b-c96953433f79",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
